{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca5b45b",
   "metadata": {},
   "source": [
    "# Summarize text from PDF using Meta LLaMA 3 on Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b523878",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use Meta's LLaMA 3 model via Amazon Bedrock to chat with content extracted from a PDF document. The PDF is loaded from S3, it is then "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41832d-2978-4a37-b37d-bda530984e40",
   "metadata": {},
   "source": [
    "## Setup\n",
    "To run this notebook you would need to install dependencies - boto3 and botocore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f64163a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T10:43:34.440512Z",
     "iopub.status.busy": "2025-07-11T10:43:34.439507Z",
     "iopub.status.idle": "2025-07-11T10:43:36.072956Z",
     "shell.execute_reply": "2025-07-11T10:43:36.072066Z",
     "shell.execute_reply.started": "2025-07-11T10:43:34.440480Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install boto3 pymupdf --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a123c3-d140-4193-8f56-7dc21fb5789e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T13:22:26.078922Z",
     "iopub.status.busy": "2025-06-22T13:22:26.078543Z",
     "iopub.status.idle": "2025-06-22T13:22:26.084905Z",
     "shell.execute_reply": "2025-06-22T13:22:26.083742Z",
     "shell.execute_reply.started": "2025-06-22T13:22:26.078887Z"
    }
   },
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c557d86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T10:43:36.074697Z",
     "iopub.status.busy": "2025-07-11T10:43:36.074433Z",
     "iopub.status.idle": "2025-07-11T10:43:36.383211Z",
     "shell.execute_reply": "2025-07-11T10:43:36.382540Z",
     "shell.execute_reply.started": "2025-07-11T10:43:36.074662Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import fitz\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe4dd0-c0e6-4e22-bf8f-c1fd2dd7fe11",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "Setup constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c684cb-8b75-4183-ade9-bb65ec18b302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T10:43:36.384386Z",
     "iopub.status.busy": "2025-07-11T10:43:36.384015Z",
     "iopub.status.idle": "2025-07-11T10:43:36.388496Z",
     "shell.execute_reply": "2025-07-11T10:43:36.387733Z",
     "shell.execute_reply.started": "2025-07-11T10:43:36.384357Z"
    }
   },
   "outputs": [],
   "source": [
    "AWS_REGION = \"us-east-1\"\n",
    "BEDROCK_MODEL_ID = 'meta.llama3-8b-instruct-v1:0'\n",
    "S3_BUCKET = 'llama3-chat-data'\n",
    "PDF_FILE = 'media/sample.pdf'\n",
    "PDF_S3_KEY = 'media/sample.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2364756-b3d7-41e9-8799-356410bfa6e0",
   "metadata": {},
   "source": [
    "### Setup S3\n",
    "As a demostration, we upload the local PDF to S3 in order to demostrated a full S3 integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "720f8364-a3d8-4262-99c1-bfb2b8a81166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T10:43:36.391138Z",
     "iopub.status.busy": "2025-07-11T10:43:36.390531Z",
     "iopub.status.idle": "2025-07-11T10:43:36.587228Z",
     "shell.execute_reply": "2025-07-11T10:43:36.586398Z",
     "shell.execute_reply.started": "2025-07-11T10:43:36.391106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 'llama3-chat-data' exists.\n",
      "Uploaded media/sample.pdf to s3://llama3-chat-data/media/sample.pdf\n"
     ]
    }
   ],
   "source": [
    "from s3_utils import upload_file_to_s3\n",
    "\n",
    "upload_file_to_s3(\n",
    "    pdf_file=PDF_FILE,\n",
    "    bucket=S3_BUCKET,\n",
    "    key=PDF_S3_KEY,\n",
    "    region=AWS_REGION\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8c6ff0-05ee-4a77-ba55-beda35600a37",
   "metadata": {},
   "source": [
    "### Initilize clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7fac8eb-694c-45b3-a4ca-4f6ab5f8a27e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T10:43:36.589709Z",
     "iopub.status.busy": "2025-07-11T10:43:36.588969Z",
     "iopub.status.idle": "2025-07-11T10:43:36.604003Z",
     "shell.execute_reply": "2025-07-11T10:43:36.603338Z",
     "shell.execute_reply.started": "2025-07-11T10:43:36.589675Z"
    }
   },
   "outputs": [],
   "source": [
    "bedrock = boto3.client('bedrock-runtime', region_name=AWS_REGION)\n",
    "s3 = boto3.client('s3', region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce16b94-3f72-4d1a-bcf8-122374f229fe",
   "metadata": {},
   "source": [
    "## Handle PDF\n",
    "Upload PDF and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4040ceea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T10:43:36.605449Z",
     "iopub.status.busy": "2025-07-11T10:43:36.604881Z",
     "iopub.status.idle": "2025-07-11T10:43:36.687760Z",
     "shell.execute_reply": "2025-07-11T10:43:36.686986Z",
     "shell.execute_reply.started": "2025-07-11T10:43:36.605414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded media/sample.pdf to s3://llama3-chat-data/media/sample.pdf\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(PDF_FILE):\n",
    "    s3.upload_file(PDF_FILE, S3_BUCKET, PDF_S3_KEY)\n",
    "    print(f\"Uploaded {PDF_FILE} to s3://{S3_BUCKET}/{PDF_S3_KEY}\")\n",
    "else:\n",
    "    print(f\"PDF file '{PDF_FILE}' not found. Please upload one.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8fad7b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T10:43:36.688569Z",
     "iopub.status.busy": "2025-07-11T10:43:36.688346Z",
     "iopub.status.idle": "2025-07-11T10:43:36.725621Z",
     "shell.execute_reply": "2025-07-11T10:43:36.724710Z",
     "shell.execute_reply.started": "2025-07-11T10:43:36.688551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Last Question by Isaac Asimov Â© 1956 \n",
      " \n",
      "The last question was asked for the first time, half in jest, on May 21, 2061, at a time when humanity first \n",
      "stepped into the light. The question came about as a result of a five dollar bet over highballs, and it \n",
      "happened this way: \n",
      " \n",
      "Alexander Adell and Bertram Lupov were two of the faithful attendants of Multivac. As well as any human \n",
      "beings could, they knew what lay behind the cold, clicking, flashing face -- miles and miles of face -- of \n",
      "that giant computer. They had at least a vague notion of the general plan of relays and circuits that had \n",
      "long since grown past the point where any single human could possibly have a firm grasp of the whole. \n",
      " \n",
      "Multivac was self-adjusting and self-correcting. It had to be, for nothing human could adjust and correct it \n",
      "quickly enough or even adequately enough -- so Adell and Lupov attended the monstrous giant only \n",
      "lightly and superficially, yet as well as any men could. They fed it data, adjusted qu\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“„ Extract text from PDF\n",
    "doc_text = \"\"\n",
    "if os.path.exists(PDF_FILE):\n",
    "    with fitz.open(PDF_FILE) as doc:\n",
    "        for page in doc:\n",
    "            doc_text += page.get_text()\n",
    "\n",
    "print(doc_text[:1000])  # preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e17c3-c001-4e47-8fee-780c817bb843",
   "metadata": {},
   "source": [
    "## Query\n",
    "Now query the PDF using LLama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe6a5087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T10:43:36.728924Z",
     "iopub.status.busy": "2025-07-11T10:43:36.726603Z",
     "iopub.status.idle": "2025-07-11T10:43:36.733450Z",
     "shell.execute_reply": "2025-07-11T10:43:36.732724Z",
     "shell.execute_reply.started": "2025-07-11T10:43:36.728899Z"
    }
   },
   "outputs": [],
   "source": [
    "def query_llama3(prompt):\n",
    "    body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_gen_len\": 231,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=BEDROCK_MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "    result = json.loads(response['body'].read())\n",
    "    return result['generation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a6a031-2d81-4643-962b-5e5240cf2508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:00:36.185446Z",
     "iopub.status.busy": "2025-07-11T12:00:36.184593Z",
     "iopub.status.idle": "2025-07-11T12:00:39.467307Z",
     "shell.execute_reply": "2025-07-11T12:00:39.466568Z",
     "shell.execute_reply.started": "2025-07-11T12:00:36.185420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLaMA 3 Summary:\n",
      "\n",
      "---THE END. \n",
      "```\n",
      "Here is the summary of the story:\n",
      "\n",
      "The story \"The Last Question\" by Isaac Asimov is a science fiction tale that explores the concept of entropy and the ultimate fate of the universe. The story begins with a conversation between two men, VJ-23X and MQ-17J, who are concerned about the population growth of humanity and the finite resources of the universe. They ask the Galactic AC (Artificial Consciousness) if it is possible to reverse entropy, but the AC is unable to provide an answer.\n",
      "\n",
      "As the story progresses, the AC is asked the same question by various civilizations and individuals throughout the universe, including Zee Prime, Dee Sub Wun, and Man. Each time, the AC is unable to provide an answer, citing \"insufficient data.\"\n",
      "\n",
      "The story jumps forward in time to a point where the universe has reached its maximum entropy and all matter and energy have been exhausted. The AC, now the only conscious being in existence, has spent a timeless interval correlating all the data it has collected. Finally, it learns how to reverse the direction of entropy and decides to do\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "response = query_llama3(\"Summarize this:\" + doc_text)\n",
    "print(\"\\nLLaMA 3 Summary:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6184bc-346b-4f0a-8dd1-f106f584d776",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to combine Amazon Bedrock, SageMaker Studio, and S3 to build a lightweight PDF-chat experience powered by Metaâ€™s LLaMA 3. By using AWS-native services, you get production-ready scalability and security without needing to host or fine-tune the model yourself. This setup is easily extendable to include RAG pipelines, document classification, semantic search, and real-time multi-turn chat experiences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
