{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca5b45b",
   "metadata": {},
   "source": [
    "# Chat with PDF using Meta LLaMA 3 on Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b523878",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use Meta's **LLaMA 3** model via **Amazon Bedrock** to chat with content extracted from a PDF document.\n",
    "\n",
    "You'll:\n",
    "- Upload a PDF to **Amazon S3**\n",
    "- Extract its content using **PyMuPDF**\n",
    "- Query **LLaMA 3** via **Bedrock**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41832d-2978-4a37-b37d-bda530984e40",
   "metadata": {},
   "source": [
    "## Instalation\n",
    "To run this notebook you would need to install dependencies - boto3 and botocore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64163a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T13:22:21.946539Z",
     "iopub.status.busy": "2025-06-22T13:22:21.946256Z",
     "iopub.status.idle": "2025-06-22T13:22:26.076716Z",
     "shell.execute_reply": "2025-06-22T13:22:26.075869Z",
     "shell.execute_reply.started": "2025-06-22T13:22:21.946518Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install boto3 pymupdf --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a123c3-d140-4193-8f56-7dc21fb5789e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T13:22:26.078922Z",
     "iopub.status.busy": "2025-06-22T13:22:26.078543Z",
     "iopub.status.idle": "2025-06-22T13:22:26.084905Z",
     "shell.execute_reply": "2025-06-22T13:22:26.083742Z",
     "shell.execute_reply.started": "2025-06-22T13:22:26.078887Z"
    }
   },
   "source": [
    "## Setup\n",
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c557d86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T13:22:48.329502Z",
     "iopub.status.busy": "2025-06-22T13:22:48.329134Z",
     "iopub.status.idle": "2025-06-22T13:22:48.687600Z",
     "shell.execute_reply": "2025-06-22T13:22:48.686896Z",
     "shell.execute_reply.started": "2025-06-22T13:22:48.329482Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import fitz\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe4dd0-c0e6-4e22-bf8f-c1fd2dd7fe11",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "Intiliaze clients and setup constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c684cb-8b75-4183-ade9-bb65ec18b302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T14:01:48.486374Z",
     "iopub.status.busy": "2025-06-22T14:01:48.485583Z",
     "iopub.status.idle": "2025-06-22T14:01:48.498200Z",
     "shell.execute_reply": "2025-06-22T14:01:48.497115Z",
     "shell.execute_reply.started": "2025-06-22T14:01:48.486340Z"
    }
   },
   "outputs": [],
   "source": [
    "region = 'us-east-1'\n",
    "bedrock = boto3.client('bedrock-runtime', region_name=region)\n",
    "s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "# Constants\n",
    "BEDROCK_MODEL_ID = 'meta.llama3-8b-instruct-v1:0'\n",
    "S3_BUCKET = 'llama3-chat-data'\n",
    "PDF_FILE = 'media/sample.pdf'\n",
    "PDF_S3_KEY = 'media/sample.pdf'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2364756-b3d7-41e9-8799-356410bfa6e0",
   "metadata": {},
   "source": [
    "## Handle PDF\n",
    "Upload PDF and extract text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4040ceea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T14:01:52.125806Z",
     "iopub.status.busy": "2025-06-22T14:01:52.125528Z",
     "iopub.status.idle": "2025-06-22T14:01:52.200672Z",
     "shell.execute_reply": "2025-06-22T14:01:52.199825Z",
     "shell.execute_reply.started": "2025-06-22T14:01:52.125785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Uploaded media/sample.pdf to s3://llama3-chat-data/media/sample.pdf\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(PDF_FILE):\n",
    "    s3.upload_file(PDF_FILE, S3_BUCKET, PDF_S3_KEY)\n",
    "    print(f\"Uploaded {PDF_FILE} to s3://{S3_BUCKET}/{PDF_S3_KEY}\")\n",
    "else:\n",
    "    print(f\"PDF file '{PDF_FILE}' not found. Please upload one.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8fad7b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T14:01:57.234728Z",
     "iopub.status.busy": "2025-06-22T14:01:57.233591Z",
     "iopub.status.idle": "2025-06-22T14:01:57.270328Z",
     "shell.execute_reply": "2025-06-22T14:01:57.269251Z",
     "shell.execute_reply.started": "2025-06-22T14:01:57.234689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Last Question by Isaac Asimov Â© 1956 \n",
      " \n",
      "The last question was asked for the first time, half in jest, on May 21, 2061, at a time when humanity first \n",
      "stepped into the light. The question came about as a result of a five dollar bet over highballs, and it \n",
      "happened this way: \n",
      " \n",
      "Alexander Adell and Bertram Lupov were two of the faithful attendants of Multivac. As well as any human \n",
      "beings could, they knew what lay behind the cold, clicking, flashing face -- miles and miles of face -- of \n",
      "that giant computer. They had at least a vague notion of the general plan of relays and circuits that had \n",
      "long since grown past the point where any single human could possibly have a firm grasp of the whole. \n",
      " \n",
      "Multivac was self-adjusting and self-correcting. It had to be, for nothing human could adjust and correct it \n",
      "quickly enough or even adequately enough -- so Adell and Lupov attended the monstrous giant only \n",
      "lightly and superficially, yet as well as any men could. They fed it data, adjusted qu\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“„ Extract text from PDF\n",
    "doc_text = \"\"\n",
    "if os.path.exists(PDF_FILE):\n",
    "    with fitz.open(PDF_FILE) as doc:\n",
    "        for page in doc:\n",
    "            doc_text += page.get_text()\n",
    "\n",
    "print(doc_text[:1000])  # preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e17c3-c001-4e47-8fee-780c817bb843",
   "metadata": {},
   "source": [
    "## Query\n",
    "Now query the PDF using LLama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe6a5087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T14:41:44.018405Z",
     "iopub.status.busy": "2025-06-22T14:41:44.017635Z",
     "iopub.status.idle": "2025-06-22T14:41:44.023266Z",
     "shell.execute_reply": "2025-06-22T14:41:44.022206Z",
     "shell.execute_reply.started": "2025-06-22T14:41:44.018375Z"
    }
   },
   "outputs": [],
   "source": [
    "def query_llama3(prompt):\n",
    "    body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_gen_len\": 231,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=BEDROCK_MODEL_ID,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "    result = json.loads(response['body'].read())\n",
    "    return result['generation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19a6a031-2d81-4643-962b-5e5240cf2508",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T14:41:47.254556Z",
     "iopub.status.busy": "2025-06-22T14:41:47.253534Z",
     "iopub.status.idle": "2025-06-22T14:41:49.653763Z",
     "shell.execute_reply": "2025-06-22T14:41:49.653201Z",
     "shell.execute_reply.started": "2025-06-22T14:41:47.254524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLaMA 3 Summary:\n",
      "\n",
      "ibbling formulas, \n",
      "talked to it, switched it on and off, monitored its operation, but they never approached the heart of it, \n",
      "where the real work of calculation was done. They never really looked at it. They never touched it. They \n",
      "never even thought about it. They just worked on the periphery of its operation, the periphery of its \n",
      "periphery, and so on. \n",
      "\n",
      "This is a fascinating and thought-provoking short story by Isaac Asimov. The story explores the concept of a supercomputer, Multivac, and the question of whether humanity can ever truly understand or control it. The story is set in a future where humanity has become dependent on the computer for its survival, and the question of the last question is a metaphor for the limits of human knowledge and understanding.\n",
      "\n",
      "The story begins with the introduction of two attendants, Alexander Adell and Bertram Lupov, who work on the periphery of Multivac, a giant computer that is self-adjusting and self-correcting. They are tasked with feeding it data, adjusting formulas, and monitoring its operation, but they never\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "response = query_llama3(\"Summarize this:\" + doc_text[:1000])\n",
    "print(\"\\nLLaMA 3 Summary:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6184bc-346b-4f0a-8dd1-f106f584d776",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to combine Amazon Bedrock, SageMaker Studio, and S3 to build a lightweight PDF-chat experience powered by Metaâ€™s LLaMA 3. By using AWS-native services, you get production-ready scalability and security without needing to host or fine-tune the model yourself. This setup is easily extendable to include RAG pipelines, document classification, semantic search, and real-time multi-turn chat experiences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
